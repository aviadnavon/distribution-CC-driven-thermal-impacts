{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd455d5b-62f9-4650-97f2-d281616ad3b8",
   "metadata": {},
   "source": [
    "# Create power flow summary statistics across timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70efc7e-f156-4f9c-b537-6df1ada5b12c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import packages and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f9d34e-abaf-45cf-9ea1-df076957ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time packages\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "## Memory packages\n",
    "import psutil # tracking memory and cpu usage\n",
    "import resource  # tracking memory and cpu usage\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "## Data structure packages\n",
    "import numpy as np \n",
    "import pandas as pd # to create data frames\n",
    "import pyarrow as pa\n",
    "\n",
    "## Math and logic packages\n",
    "import random\n",
    "import math\n",
    "\n",
    "## Load & Save data packages\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "\n",
    "## Plotting packages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Packages for merging dictionaries\n",
    "from __future__ import annotations\n",
    "import os\n",
    "from typing import List, Dict, Any, Iterable, Optional, Tuple, Union\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from joblib import load as joblib_load, dump as joblib_dump\n",
    "\n",
    "## Internal functions packages\n",
    "from src import figure_ops\n",
    "from src import input_ops\n",
    "from src import df_ops\n",
    "from src import file_ops\n",
    "\n",
    "## Define functions for Memory usage\n",
    "## --- Memory functions ---\n",
    "def print_memory_usage(msg=\"\"):\n",
    "    mem = psutil.virtual_memory()\n",
    "    print(f\"{msg} | Memory used: {mem.used / 1e9:.2f} GB / {mem.total / 1e9:.2f} GB\")\n",
    "    \n",
    "def print_self_memory_usage(msg=\"\"):\n",
    "    usage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "    # On Linux, ru_maxrss is in kilobytes\n",
    "    print(f\"{msg} | Memory used by this process: {usage / 1e6:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d565179-3c41-4d51-90a4-87aec947c219",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load config file with scenarios and parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0f53dd9-4e51-45c3-886e-5a02e1266915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smart_ds_year: 2018  \n",
      "\n",
      "TGW_years_scenarios: {'2018': ['historical']} \n",
      "\n",
      "city region: {'GSO': ['rural']} \n",
      "\n",
      "Output_pf_path: /nfs/turbo/seas-mtcraig-climate/Aviad/OpenDSS/results/data/network_performance/MLP/snapshot/2018/\n"
     ]
    }
   ],
   "source": [
    "config_file_name = 'opendss_config1'; config_path = f\"/home/aviadf/opendss/notebooks/config/{config_file_name}.yaml\"; config = input_ops.load_config(config_path)\n",
    "# pprint.pprint(config, sort_dicts=False) # print config\n",
    "\n",
    "CITY_REGIONS_TO_RUN = config['CITY_REGIONS_TO_RUN']\n",
    "\n",
    "TGW_years_scenarios = config['TGW_years_scenarios']\n",
    "\n",
    "smart_ds_year = config['smart_ds_years'][0]\n",
    "\n",
    "smart_ds_load_path = config['smart_ds_load_path'] + f\"/{smart_ds_year}\" # path to procesed smart-ds resstock data \n",
    "\n",
    "## Initialize parameters for saving paths\n",
    "output_pf_path = config['output_pf_path']\n",
    "    \n",
    "solution_mode = config['solution_mode']\n",
    "\n",
    "demand_mode = config['demand_mode']\n",
    "\n",
    "## Define variables to create list of mdh to run\n",
    "start_month_mdh = config['start_month_mdh'] \n",
    "end_month_mdh = config['end_month_mdh']\n",
    "top_percent_mdh = config['top_percent_mdh']\n",
    "\n",
    "top_n_hours = int(np.ceil(8760*top_percent_mdh/100)) # calculate top city demand hours to run (top_percent_mdh% of hours of the year)\n",
    "\n",
    "print(f\"smart_ds_year: {smart_ds_year}  \\n\\nTGW_years_scenarios: {TGW_years_scenarios} \\n\\ncity region: {CITY_REGIONS_TO_RUN} \\n\\nOutput_pf_path: {output_pf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05323d2c-ca21-47a6-b102-a4776a167c57",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create dictionary w/ summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a0cd8-2aca-42ee-b418-30456615204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Configuration (example)\n",
    "# ---------------------------\n",
    "# Inputs you already have in your environment:\n",
    "# output_pf_path = \"/path/to/network_performance/...\"  # from your config\n",
    "smart_ds_year = '2018'\n",
    "city = 'GSO'\n",
    "region = 'rural'\n",
    "\n",
    "# Percent-of-peak range to analyze (e.g., top 0–10% hours)\n",
    "start_row_percent = 0\n",
    "top_percent_mdh = 20\n",
    "\n",
    "# Baseline (historical 2018)\n",
    "baseline_TGW_scenario = 'historical'\n",
    "baseline_TGW_year = '2018'\n",
    "\n",
    "# Future (e.g., rcp45hotter 2058)\n",
    "future_TGW_scenario = 'rcp45hotter'\n",
    "future_TGW_year = '2058'\n",
    "\n",
    "# File names\n",
    "transformers_file_name = f\"transformers_top_{start_row_percent}_{top_percent_mdh}_percent\"\n",
    "lines_file_name        = f\"lines_top_{start_row_percent}_{top_percent_mdh}_percent\"\n",
    "\n",
    "# ---------------------------\n",
    "# Helper: get DataFrame from nested dictionary\n",
    "# ---------------------------\n",
    "def extract_df(nested_dict, weather_year, scenario, smart_ds_year, city, region):\n",
    "    \"\"\"\n",
    "    Extract a DataFrame from nested joblib dicts.\n",
    "    \"\"\"\n",
    "    return nested_dict[(weather_year, scenario)][(smart_ds_year, city, region)].copy()\n",
    "\n",
    "# ---------------------------\n",
    "# Load baseline & future merged dictionaries → DataFrames\n",
    "# ---------------------------\n",
    "\n",
    "## Transformers\n",
    "# Baseline\n",
    "predictions_dir_baseline = os.path.join(\n",
    "    output_pf_path, f\"{city}/{region}/{baseline_TGW_scenario}/{baseline_TGW_year}\"\n",
    ")\n",
    "xfer_path_baseline = os.path.join(predictions_dir_baseline, f\"{transformers_file_name}.joblib\")\n",
    "xfer_baseline_obj = joblib.load(xfer_path_baseline)\n",
    "xfer_df_baseline = extract_df(xfer_baseline_obj, '2018', 'historical', smart_ds_year, city, region)\n",
    "\n",
    "# Future\n",
    "predictions_dir_future = os.path.join(\n",
    "    output_pf_path, f\"{city}/{region}/{future_TGW_scenario}/{future_TGW_year}\"\n",
    ")\n",
    "xfer_path_future = os.path.join(predictions_dir_future, f\"{transformers_file_name}.joblib\")\n",
    "xfer_future_obj = joblib.load(xfer_path_future)\n",
    "xfer_df_future = extract_df(xfer_future_obj, '2058', 'rcp45hotter', smart_ds_year, city, region)\n",
    "\n",
    "## Lines\n",
    "# Baseline\n",
    "# (use the LINES filename, not transformer one)                                  \n",
    "lines_path_baseline = os.path.join(predictions_dir_baseline, f\"{lines_file_name}.joblib\") \n",
    "lines_baseline_obj = joblib.load(lines_path_baseline)\n",
    "lines_df_baseline = extract_df(lines_baseline_obj, '2018', 'historical', smart_ds_year, city, region)\n",
    "\n",
    "# Future\n",
    "# (use the LINES filename, not transformer one)                                 \n",
    "lines_path_future = os.path.join(predictions_dir_future, f\"{lines_file_name}.joblib\")     \n",
    "lines_future_obj = joblib.load(lines_path_future)\n",
    "lines_df_future = extract_df(lines_future_obj, '2058', 'rcp45hotter', smart_ds_year, city, region)\n",
    "\n",
    "# ---------------------------\n",
    "# Basic sanity & column normalization\n",
    "# ---------------------------\n",
    "xfer_required_cols = {\n",
    "    'Transformer', 'Loading [%]', 'row_i', 'month', 'day', 'hour',\n",
    "    'Bus', 'Lat', 'Long', 'Num windings', 'Num phases', 'KV rating [kV]', 'kVA rating [kVA]'\n",
    "}\n",
    "missing_baseline = xfer_required_cols - set(xfer_df_baseline.columns)\n",
    "missing_future = xfer_required_cols - set(xfer_df_future.columns)\n",
    "if missing_baseline:\n",
    "    print(f\"Warning: baseline (transformers) missing columns: {missing_baseline}\")  \n",
    "if missing_future:\n",
    "    print(f\"Warning: future (transformers) missing columns: {missing_future}\")      \n",
    "\n",
    "lines_required_cols = {\n",
    "    'month', 'day', 'hour', 'row_i', 'Line', 'LineCode',\n",
    "    'Length [km]', 'From_Lat', 'To_Lat', 'From_Long', 'To_Long',\n",
    "    'NormAmps [A]', 'Nominal V [kV]', 'Loading [%]'\n",
    "}\n",
    "\n",
    "# validate against LINES dfs (not transformer dfs)                                 \n",
    "missing_baseline_lines = lines_required_cols - set(lines_df_baseline.columns)      \n",
    "missing_future_lines   = lines_required_cols - set(lines_df_future.columns)        \n",
    "if missing_baseline_lines:\n",
    "    print(f\"Warning: baseline (lines) missing columns: {missing_baseline_lines}\")  \n",
    "if missing_future_lines:\n",
    "    print(f\"Warning: future (lines) missing columns: {missing_future_lines}\")      \n",
    "\n",
    "# Ensure baseline/future have scenario tags (not strictly needed for stats, but nice to keep)\n",
    "xfer_df_baseline = xfer_df_baseline.copy()\n",
    "xfer_df_future = xfer_df_future.copy()\n",
    "xfer_df_baseline['__scenario__'] = f'{baseline_TGW_scenario}_{baseline_TGW_year}'\n",
    "xfer_df_future['__scenario__']   = f'{future_TGW_scenario}_{future_TGW_year}'\n",
    "\n",
    "lines_df_baseline = lines_df_baseline.copy()\n",
    "lines_df_future = lines_df_future.copy()\n",
    "lines_df_baseline['__scenario__'] = f'{baseline_TGW_scenario}_{baseline_TGW_year}'\n",
    "lines_df_future['__scenario__']   = f'{future_TGW_scenario}_{future_TGW_year}'\n",
    "\n",
    "# ---------------------------\n",
    "# Static attributes\n",
    "# ---------------------------\n",
    "xfer_static_cols  = ['Transformer', 'Bus', 'Lat', 'Long', 'Num windings', 'Num phases', 'KV rating [kV]', 'kVA rating [kVA]']\n",
    "lines_static_cols = ['Line', 'LineCode', 'Length [km]', 'From_Lat', 'To_Lat', 'From_Long', 'To_Long', 'NormAmps [A]', 'Nominal V [kV]']\n",
    "\n",
    "xfer_static_df = (\n",
    "    pd.concat([xfer_df_baseline[xfer_static_cols], xfer_df_future[xfer_static_cols]], ignore_index=True)\n",
    "      .drop_duplicates(subset=['Transformer'])\n",
    "      .set_index('Transformer')\n",
    ")\n",
    "\n",
    "# lines_static_df must be built from LINES dfs and indexed by 'Line'               \n",
    "lines_static_df = (                                                                \n",
    "    pd.concat([lines_df_baseline[lines_static_cols], lines_df_future[lines_static_cols]], ignore_index=True)  \n",
    "      .drop_duplicates(subset=['Line'])                                                                                  \n",
    "      .set_index('Line')                                                                                                  \n",
    ")\n",
    "\n",
    "# =================================================================================\n",
    "# ==================== TRANSFORMERS PIPELINE (unchanged logic) ====================\n",
    "# =================================================================================\n",
    "\n",
    "# ---------------------------\n",
    "# Summary stats per transformer for each scenario\n",
    "# ---------------------------\n",
    "def _scenario_summary_xfer(df: pd.DataFrame, scenario_tag: str) -> pd.DataFrame:   \n",
    "    \"\"\"\n",
    "    Compute per-transformer summary stats on 'Loading [%]' across all row_i in the given df.\n",
    "    \"\"\"\n",
    "    grp = df.groupby('Transformer')['Loading [%]']\n",
    "    out = pd.DataFrame({\n",
    "        f'90th_loading_{scenario_tag}': grp.quantile(0.90),\n",
    "        f'95th_loading_{scenario_tag}': grp.quantile(0.95),\n",
    "        f'99th_loading_{scenario_tag}': grp.quantile(0.99),\n",
    "        f'min_loading_{scenario_tag}': grp.min(),\n",
    "        f'max_loading_{scenario_tag}': grp.max(),\n",
    "        f'median_loading_{scenario_tag}': grp.median(),\n",
    "        f'average_loading_{scenario_tag}': grp.mean(),\n",
    "    })\n",
    "    # Hours over thresholds\n",
    "    for thr in [70, 80, 90, 100]:\n",
    "        out[f'hours_over_{thr}_loading_{scenario_tag}'] = df.assign(\n",
    "            over=(df['Loading [%]'] >= thr).astype(int)\n",
    "        ).groupby('Transformer')['over'].sum()\n",
    "    return out\n",
    "\n",
    "summ_baseline_xfer = _scenario_summary_xfer(xfer_df_baseline, f\"{baseline_TGW_scenario}_{baseline_TGW_year}\")  \n",
    "summ_future_xfer   = _scenario_summary_xfer(xfer_df_future,   f\"{future_TGW_scenario}_{future_TGW_year}\")      \n",
    "\n",
    "# ---------------------------\n",
    "# Difference stats (future - baseline) using only COMMON MDH per transformer\n",
    "# ---------------------------\n",
    "# Prepare smaller frames for merging on (Transformer, month, day, hour)\n",
    "cols_mdh_xfer = ['Transformer', 'month', 'day', 'hour', 'Loading [%]']             \n",
    "\n",
    "b_mdh_xfer = xfer_df_baseline[cols_mdh_xfer].rename(columns={'Loading [%]': 'loading_baseline'})  \n",
    "f_mdh_xfer = xfer_df_future[cols_mdh_xfer].rename(columns={'Loading [%]': 'loading_future'})      \n",
    "\n",
    "merged_mdh_xfer = pd.merge(                                                         \n",
    "    b_mdh_xfer, f_mdh_xfer, on=['Transformer', 'month', 'day', 'hour'], how='inner' \n",
    ")\n",
    "\n",
    "# Compute pointwise differences (future - baseline) and aggregate per transformer\n",
    "if len(merged_mdh_xfer) == 0:                                                       \n",
    "    # No common MDH; create empty with NaNs\n",
    "    diff_stats_xfer = pd.DataFrame(index=xfer_static_df.index, data={               \n",
    "        f'min_loading_diff_{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}': np.nan,\n",
    "        f'average_loading_diff_{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}': np.nan,\n",
    "        f'max_loading_diff_{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}': np.nan,\n",
    "    })\n",
    "else:\n",
    "    merged_mdh_xfer = merged_mdh_xfer.assign(diff=merged_mdh_xfer['loading_future'] - merged_mdh_xfer['loading_baseline'])  \n",
    "    gdiff = merged_mdh_xfer.groupby('Transformer')['diff']                           \n",
    "    diff_stats_xfer = pd.DataFrame({                                                 \n",
    "        f'min_loading_diff_{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}': gdiff.min(),\n",
    "        f'average_loading_diff_{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}': gdiff.mean(),\n",
    "        f'max_loading_diff_{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}': gdiff.max(),\n",
    "    })\n",
    "\n",
    "# ---------------------------\n",
    "# Assemble the final TRANSFORMERS summary table\n",
    "# ---------------------------\n",
    "summary_df_xfer = (                                                                 \n",
    "    xfer_static_df\n",
    "    .join(summ_baseline_xfer, how='outer')                                          \n",
    "    .join(summ_future_xfer,   how='outer')                                          \n",
    "    .join(diff_stats_xfer,    how='left')                                           \n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Optional: tidy column order (static → baseline stats → future stats → diff stats)\n",
    "def _order_cols_xfer(df: pd.DataFrame) -> list:                                     \n",
    "    base_tag = f\"{baseline_TGW_scenario}_{baseline_TGW_year}\"\n",
    "    fut_tag  = f\"{future_TGW_scenario}_{future_TGW_year}\"\n",
    "    diff_suf = f\"{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}\"\n",
    "\n",
    "    stat_names = [\n",
    "        '90th_loading', '95th_loading', '99th_loading',\n",
    "        'min_loading', 'max_loading', 'median_loading', 'average_loading',\n",
    "        'hours_over_70_loading', 'hours_over_80_loading',\n",
    "        'hours_over_90_loading', 'hours_over_100_loading'\n",
    "    ]\n",
    "\n",
    "    static = xfer_static_cols\n",
    "    baseline_cols = [f\"{s}_{base_tag}\" for s in stat_names]\n",
    "    future_cols   = [f\"{s}_{fut_tag}\"  for s in stat_names]\n",
    "    diff_cols = [\n",
    "        f\"min_loading_diff_{diff_suf}\",\n",
    "        f\"average_loading_diff_{diff_suf}\",\n",
    "        f\"max_loading_diff_{diff_suf}\",\n",
    "    ]\n",
    "\n",
    "    ordered = [c for c in static if c in df.columns] \\\n",
    "            + [c for c in baseline_cols if c in df.columns] \\\n",
    "            + [c for c in future_cols if c in df.columns] \\\n",
    "            + [c for c in diff_cols if c in df.columns]\n",
    "    leftovers = [c for c in df.columns if c not in ordered]\n",
    "    return ordered + leftovers\n",
    "\n",
    "summary_df_xfer = summary_df_xfer[_order_cols_xfer(summary_df_xfer)]               \n",
    "\n",
    "# ---------------------------\n",
    "# Provide dicts + save (TRANSFORMERS)\n",
    "# ---------------------------\n",
    "transformers_dict_region_p_0_10_summary_by_transformer = {\n",
    "    row['Transformer']: {k: row[k] for k in summary_df_xfer.columns if k != 'Transformer'}\n",
    "    for _, row in summary_df_xfer.iterrows()\n",
    "}\n",
    "\n",
    "transformers_dict_region_p_0_10_summary_by_scenario = {}                           \n",
    "transformers_dict_region_p_0_10_summary_by_scenario[(future_TGW_year, future_TGW_scenario)] = {}\n",
    "transformers_dict_region_p_0_10_summary_by_scenario[(future_TGW_year, future_TGW_scenario)][(smart_ds_year, city, region)] = summary_df_xfer\n",
    "\n",
    "xfer_summary_save_path = os.path.join(                                             \n",
    "    predictions_dir_future, f\"{transformers_file_name}_summary.joblib\"\n",
    ")\n",
    "joblib.dump(transformers_dict_region_p_0_10_summary_by_scenario, xfer_summary_save_path)  \n",
    "\n",
    "print(f\"Transformers summarized: {len(summary_df_xfer)}\")\n",
    "display(summary_df_xfer.head(3))\n",
    "\n",
    "\n",
    "# =================================================================================\n",
    "# ========================= LINES PIPELINE (NEW SECTION) ==========================\n",
    "# =================================================================================\n",
    "\n",
    "# ---------------------------\n",
    "# Summary stats per LINE for each scenario\n",
    "# ---------------------------\n",
    "def _scenario_summary_line(df: pd.DataFrame, scenario_tag: str) -> pd.DataFrame:   \n",
    "    \"\"\"\n",
    "    Compute per-line summary stats on 'Loading [%]' across all row_i in the given df.\n",
    "    \"\"\"\n",
    "    grp = df.groupby('Line')['Loading [%]']\n",
    "    out = pd.DataFrame({\n",
    "        f'90th_loading_{scenario_tag}': grp.quantile(0.90),\n",
    "        f'95th_loading_{scenario_tag}': grp.quantile(0.95),\n",
    "        f'99th_loading_{scenario_tag}': grp.quantile(0.99),\n",
    "        f'min_loading_{scenario_tag}': grp.min(),\n",
    "        f'max_loading_{scenario_tag}': grp.max(),\n",
    "        f'median_loading_{scenario_tag}': grp.median(),\n",
    "        f'average_loading_{scenario_tag}': grp.mean(),\n",
    "    })\n",
    "    for thr in [70, 80, 90, 100]:\n",
    "        out[f'hours_over_{thr}_loading_{scenario_tag}'] = df.assign(\n",
    "            over=(df['Loading [%]'] >= thr).astype(int)\n",
    "        ).groupby('Line')['over'].sum()\n",
    "    return out\n",
    "\n",
    "summ_baseline_line = _scenario_summary_line(lines_df_baseline, f\"{baseline_TGW_scenario}_{baseline_TGW_year}\")  \n",
    "summ_future_line   = _scenario_summary_line(lines_df_future,   f\"{future_TGW_scenario}_{future_TGW_year}\")      \n",
    "\n",
    "# ---------------------------\n",
    "# Difference stats (future - baseline) using only COMMON MDH per LINE\n",
    "# ---------------------------\n",
    "cols_mdh_line = ['Line', 'month', 'day', 'hour', 'Loading [%]']                     \n",
    "\n",
    "b_mdh_line = lines_df_baseline[cols_mdh_line].rename(columns={'Loading [%]': 'loading_baseline'})  \n",
    "f_mdh_line = lines_df_future[cols_mdh_line].rename(columns={'Loading [%]': 'loading_future'})      \n",
    "\n",
    "merged_mdh_line = pd.merge(                                                          \n",
    "    b_mdh_line, f_mdh_line, on=['Line', 'month', 'day', 'hour'], how='inner'         \n",
    ")\n",
    "\n",
    "if len(merged_mdh_line) == 0:                                                        \n",
    "    diff_stats_line = pd.DataFrame(index=lines_static_df.index, data={               \n",
    "        f'min_loading_diff_{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}': np.nan,\n",
    "        f'average_loading_diff_{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}': np.nan,\n",
    "        f'max_loading_diff_{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}': np.nan,\n",
    "    })\n",
    "else:\n",
    "    merged_mdh_line = merged_mdh_line.assign(diff=merged_mdh_line['loading_future'] - merged_mdh_line['loading_baseline'])  \n",
    "    gdiff_line = merged_mdh_line.groupby('Line')['diff']                                                                    \n",
    "    diff_stats_line = pd.DataFrame({                                                                                        \n",
    "        f'min_loading_diff_{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}': gdiff_line.min(),\n",
    "        f'average_loading_diff_{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}': gdiff_line.mean(),\n",
    "        f'max_loading_diff_{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}': gdiff_line.max(),\n",
    "    })\n",
    "\n",
    "# ---------------------------\n",
    "# Assemble the final LINES summary table\n",
    "# ---------------------------\n",
    "summary_df_line = (                                                                   \n",
    "    lines_static_df\n",
    "    .join(summ_baseline_line, how='outer')                                            \n",
    "    .join(summ_future_line,   how='outer')                                            \n",
    "    .join(diff_stats_line,    how='left')                                             \n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "def _order_cols_line(df: pd.DataFrame) -> list:                                       \n",
    "    base_tag = f\"{baseline_TGW_scenario}_{baseline_TGW_year}\"\n",
    "    fut_tag  = f\"{future_TGW_scenario}_{future_TGW_year}\"\n",
    "    diff_suf = f\"{future_TGW_scenario}_{future_TGW_year}_vs_{baseline_TGW_scenario}_{baseline_TGW_year}\"\n",
    "\n",
    "    stat_names = [\n",
    "        '90th_loading', '95th_loading', '99th_loading',\n",
    "        'min_loading', 'max_loading', 'median_loading', 'average_loading',\n",
    "        'hours_over_70_loading', 'hours_over_80_loading',\n",
    "        'hours_over_90_loading', 'hours_over_100_loading'\n",
    "    ]\n",
    "\n",
    "    static = lines_static_cols\n",
    "    baseline_cols = [f\"{s}_{base_tag}\" for s in stat_names]\n",
    "    future_cols   = [f\"{s}_{fut_tag}\"  for s in stat_names]\n",
    "    diff_cols = [\n",
    "        f\"min_loading_diff_{diff_suf}\",\n",
    "        f\"average_loading_diff_{diff_suf}\",\n",
    "        f\"max_loading_diff_{diff_suf}\",\n",
    "    ]\n",
    "\n",
    "    ordered = [c for c in static if c in df.columns] \\\n",
    "            + [c for c in baseline_cols if c in df.columns] \\\n",
    "            + [c for c in future_cols if c in df.columns] \\\n",
    "            + [c for c in diff_cols if c in df.columns]\n",
    "    leftovers = [c for c in df.columns if c not in ordered]\n",
    "    return ordered + leftovers\n",
    "\n",
    "summary_df_line = summary_df_line[_order_cols_line(summary_df_line)]                  \n",
    "\n",
    "# ---------------------------\n",
    "# Provide dicts + save (LINES)\n",
    "# ---------------------------\n",
    "lines_dict_region_p_0_10_summary_by_line = {                                         \n",
    "    row['Line']: {k: row[k] for k in summary_df_line.columns if k != 'Line'}\n",
    "    for _, row in summary_df_line.iterrows()\n",
    "}\n",
    "\n",
    "lines_dict_region_p_0_10_summary_by_scenario = {}                                     \n",
    "lines_dict_region_p_0_10_summary_by_scenario[(future_TGW_year, future_TGW_scenario)] = {}  \n",
    "lines_dict_region_p_0_10_summary_by_scenario[(future_TGW_year, future_TGW_scenario)][(smart_ds_year, city, region)] = summary_df_line  \n",
    "\n",
    "lines_summary_save_path = os.path.join(                                               \n",
    "    predictions_dir_future, f\"{lines_file_name}_summary.joblib\"\n",
    ")\n",
    "joblib.dump(lines_dict_region_p_0_10_summary_by_scenario, lines_summary_save_path)    \n",
    "\n",
    "print(f\"Lines summarized: {len(summary_df_line)}\")                                    \n",
    "display(summary_df_line.head(3))                                                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6699fe89-761f-43e9-9c58-70cf27d0db87",
   "metadata": {},
   "source": [
    "## Load dictionary w/ summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ebc413e-4c83-4129-9fd8-a56f9d53231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_ds_year = '2018'\n",
    "city = 'GSO'\n",
    "region = 'rural'\n",
    "\n",
    "# Percent-of-peak range to analyze (e.g., top 0–10% hours)\n",
    "start_row_percent = 0\n",
    "top_percent_mdh = 10\n",
    "\n",
    "# Baseline (historical 2018)\n",
    "baseline_TGW_scenario = 'historical'\n",
    "baseline_TGW_year = '2018'\n",
    "\n",
    "# Future (e.g., rcp45hotter 2058)\n",
    "future_TGW_scenario = 'rcp45hotter'\n",
    "future_TGW_year = '2058'\n",
    "\n",
    "predictions_dir_baseline = os.path.join(output_pf_path, f\"{city}/{region}/{baseline_TGW_scenario}/{baseline_TGW_year}\")\n",
    "\n",
    "# Future\n",
    "predictions_dir_future = os.path.join(output_pf_path, f\"{city}/{region}/{future_TGW_scenario}/{future_TGW_year}\")\n",
    "\n",
    "# File names\n",
    "transformers_file_name = f\"transformers_top_{start_row_percent}_{top_percent_mdh}_percent\"\n",
    "lines_file_name        = f\"lines_top_{start_row_percent}_{top_percent_mdh}_percent\"\n",
    "\n",
    "xfer_summary_save_path = os.path.join(predictions_dir_future, f\"{transformers_file_name}_summary.joblib\")\n",
    "transformers_dict_region_p_0_10_summary_by_scenario = joblib.load(xfer_summary_save_path)  \n",
    "\n",
    "lines_summary_save_path = os.path.join(predictions_dir_future, f\"{lines_file_name}_summary.joblib\")\n",
    "lines_dict_region_p_0_10_summary_by_scenario = joblib.load(lines_summary_save_path)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2139eb3c-301c-489f-8b7e-6bce4fa8d509",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Print dictionary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c349e5e1-18b4-4cd9-8b12-e62741c65b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary nested keys structure:\n",
      "level 1:\n",
      "dict_keys([('2058', 'rcp45hotter')])\n",
      "\n",
      "level 2:\n",
      "dict_keys([('2018', 'GSO', 'rural')])\n",
      "\n",
      "Dictionary sample keys and dataframe structure:\n",
      "Level 1 - sample keys (1 total): [('2058', 'rcp45hotter')]\n",
      "Level 2 - sample keys (1 total): [('2018', 'GSO', 'rural')]\n",
      "\n",
      "Reached DataFrame at level 2\n",
      "Shape: (3367, 33)\n",
      "Index type: <class 'pandas.core.indexes.range.RangeIndex'>\n",
      "Columns: ['Transformer', 'Bus', 'Lat', 'Long', 'Num windings', 'Num phases', 'KV rating [kV]', 'kVA rating [kVA]', '90th_loading_historical_2018', '95th_loading_historical_2018', '99th_loading_historical_2018', 'min_loading_historical_2018', 'max_loading_historical_2018', 'median_loading_historical_2018', 'average_loading_historical_2018', 'hours_over_70_loading_historical_2018', 'hours_over_80_loading_historical_2018', 'hours_over_90_loading_historical_2018', 'hours_over_100_loading_historical_2018', '90th_loading_rcp45hotter_2058', '95th_loading_rcp45hotter_2058', '99th_loading_rcp45hotter_2058', 'min_loading_rcp45hotter_2058', 'max_loading_rcp45hotter_2058', 'median_loading_rcp45hotter_2058', 'average_loading_rcp45hotter_2058', 'hours_over_70_loading_rcp45hotter_2058', 'hours_over_80_loading_rcp45hotter_2058', 'hours_over_90_loading_rcp45hotter_2058', 'hours_over_100_loading_rcp45hotter_2058', 'min_loading_diff_rcp45hotter_2058_vs_historical_2018', 'average_loading_diff_rcp45hotter_2058_vs_historical_2018', 'max_loading_diff_rcp45hotter_2058_vs_historical_2018']\n",
      "Dtypes:\n",
      "Transformer                                                  object\n",
      "Bus                                                          object\n",
      "Lat                                                         float64\n",
      "Long                                                        float64\n",
      "Num windings                                                  int64\n",
      "Num phases                                                    int64\n",
      "KV rating [kV]                                               object\n",
      "kVA rating [kVA]                                            float64\n",
      "90th_loading_historical_2018                                float64\n",
      "95th_loading_historical_2018                                float64\n",
      "99th_loading_historical_2018                                float64\n",
      "min_loading_historical_2018                                 float64\n",
      "max_loading_historical_2018                                 float64\n",
      "median_loading_historical_2018                              float64\n",
      "average_loading_historical_2018                             float64\n",
      "hours_over_70_loading_historical_2018                         int64\n",
      "hours_over_80_loading_historical_2018                         int64\n",
      "hours_over_90_loading_historical_2018                         int64\n",
      "hours_over_100_loading_historical_2018                        int64\n",
      "90th_loading_rcp45hotter_2058                               float64\n",
      "95th_loading_rcp45hotter_2058                               float64\n",
      "99th_loading_rcp45hotter_2058                               float64\n",
      "min_loading_rcp45hotter_2058                                float64\n",
      "max_loading_rcp45hotter_2058                                float64\n",
      "median_loading_rcp45hotter_2058                             float64\n",
      "average_loading_rcp45hotter_2058                            float64\n",
      "hours_over_70_loading_rcp45hotter_2058                        int64\n",
      "hours_over_80_loading_rcp45hotter_2058                        int64\n",
      "hours_over_90_loading_rcp45hotter_2058                        int64\n",
      "hours_over_100_loading_rcp45hotter_2058                       int64\n",
      "min_loading_diff_rcp45hotter_2058_vs_historical_2018        float64\n",
      "average_loading_diff_rcp45hotter_2058_vs_historical_2018    float64\n",
      "max_loading_diff_rcp45hotter_2058_vs_historical_2018        float64\n",
      "dtype: object\n",
      "\n",
      "Selected leaf #0 at path: ('2058', 'rcp45hotter') -> ('2018', 'GSO', 'rural')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transformer</th>\n",
       "      <th>Bus</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Num windings</th>\n",
       "      <th>Num phases</th>\n",
       "      <th>KV rating [kV]</th>\n",
       "      <th>kVA rating [kVA]</th>\n",
       "      <th>90th_loading_historical_2018</th>\n",
       "      <th>95th_loading_historical_2018</th>\n",
       "      <th>...</th>\n",
       "      <th>max_loading_rcp45hotter_2058</th>\n",
       "      <th>median_loading_rcp45hotter_2058</th>\n",
       "      <th>average_loading_rcp45hotter_2058</th>\n",
       "      <th>hours_over_70_loading_rcp45hotter_2058</th>\n",
       "      <th>hours_over_80_loading_rcp45hotter_2058</th>\n",
       "      <th>hours_over_90_loading_rcp45hotter_2058</th>\n",
       "      <th>hours_over_100_loading_rcp45hotter_2058</th>\n",
       "      <th>min_loading_diff_rcp45hotter_2058_vs_historical_2018</th>\n",
       "      <th>average_loading_diff_rcp45hotter_2058_vs_historical_2018</th>\n",
       "      <th>max_loading_diff_rcp45hotter_2058_vs_historical_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sb1_rhs1_1247_trans_29</td>\n",
       "      <td>sb1_rhs1_1247_node_1_3</td>\n",
       "      <td>36.269960</td>\n",
       "      <td>-79.611380</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[69.0, 12.47]</td>\n",
       "      <td>15360.0</td>\n",
       "      <td>38.522244</td>\n",
       "      <td>39.947331</td>\n",
       "      <td>...</td>\n",
       "      <td>48.807713</td>\n",
       "      <td>35.372810</td>\n",
       "      <td>35.526961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.667012</td>\n",
       "      <td>2.355397</td>\n",
       "      <td>10.723921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sb2_rhs0_1247_trans_51</td>\n",
       "      <td>sb2_rhs0_1247_node_2_10</td>\n",
       "      <td>36.198719</td>\n",
       "      <td>-79.612273</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[69.0, 12.47]</td>\n",
       "      <td>28800.0</td>\n",
       "      <td>37.788189</td>\n",
       "      <td>39.361764</td>\n",
       "      <td>...</td>\n",
       "      <td>48.071340</td>\n",
       "      <td>33.635677</td>\n",
       "      <td>33.555932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.991210</td>\n",
       "      <td>1.867430</td>\n",
       "      <td>10.591260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sb8_rhs2_1247_trans_2</td>\n",
       "      <td>sb8_rhs2_1247_node_8_9</td>\n",
       "      <td>36.180056</td>\n",
       "      <td>-79.531106</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[69.0, 12.47]</td>\n",
       "      <td>15360.0</td>\n",
       "      <td>29.834240</td>\n",
       "      <td>30.887339</td>\n",
       "      <td>...</td>\n",
       "      <td>38.274902</td>\n",
       "      <td>28.061898</td>\n",
       "      <td>28.061863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.923320</td>\n",
       "      <td>2.588110</td>\n",
       "      <td>8.947509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Transformer                      Bus        Lat       Long  \\\n",
       "0  sb1_rhs1_1247_trans_29   sb1_rhs1_1247_node_1_3  36.269960 -79.611380   \n",
       "1  sb2_rhs0_1247_trans_51  sb2_rhs0_1247_node_2_10  36.198719 -79.612273   \n",
       "2   sb8_rhs2_1247_trans_2   sb8_rhs2_1247_node_8_9  36.180056 -79.531106   \n",
       "\n",
       "   Num windings  Num phases KV rating [kV]  kVA rating [kVA]  \\\n",
       "0             2           3  [69.0, 12.47]           15360.0   \n",
       "1             2           3  [69.0, 12.47]           28800.0   \n",
       "2             2           3  [69.0, 12.47]           15360.0   \n",
       "\n",
       "   90th_loading_historical_2018  95th_loading_historical_2018  ...  \\\n",
       "0                     38.522244                     39.947331  ...   \n",
       "1                     37.788189                     39.361764  ...   \n",
       "2                     29.834240                     30.887339  ...   \n",
       "\n",
       "   max_loading_rcp45hotter_2058  median_loading_rcp45hotter_2058  \\\n",
       "0                     48.807713                        35.372810   \n",
       "1                     48.071340                        33.635677   \n",
       "2                     38.274902                        28.061898   \n",
       "\n",
       "   average_loading_rcp45hotter_2058  hours_over_70_loading_rcp45hotter_2058  \\\n",
       "0                         35.526961                                       0   \n",
       "1                         33.555932                                       0   \n",
       "2                         28.061863                                       0   \n",
       "\n",
       "   hours_over_80_loading_rcp45hotter_2058  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "\n",
       "   hours_over_90_loading_rcp45hotter_2058  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "\n",
       "   hours_over_100_loading_rcp45hotter_2058  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "\n",
       "   min_loading_diff_rcp45hotter_2058_vs_historical_2018  \\\n",
       "0                                          -6.667012      \n",
       "1                                          -7.991210      \n",
       "2                                          -4.923320      \n",
       "\n",
       "   average_loading_diff_rcp45hotter_2058_vs_historical_2018  \\\n",
       "0                                           2.355397          \n",
       "1                                           1.867430          \n",
       "2                                           2.588110          \n",
       "\n",
       "   max_loading_diff_rcp45hotter_2058_vs_historical_2018  \n",
       "0                                          10.723921     \n",
       "1                                          10.591260     \n",
       "2                                           8.947509     \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Dictionary nested keys structure:\")\n",
    "file_ops.print_nested_keys_structure(transformers_dict_region_p_0_10_summary_by_scenario)       \n",
    "\n",
    "print(\"Dictionary sample keys and dataframe structure:\")\n",
    "file_ops.print_nested_dict_key_examples_and_dataframe_details(transformers_dict_region_p_0_10_summary_by_scenario)\n",
    "\n",
    "# Show head(n) of the key_number leaf \n",
    "df = file_ops.return_leaf_dataframe(transformers_dict_region_p_0_10_summary_by_scenario, key_number=0, n=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opendss_env2",
   "language": "python",
   "name": "opendss_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
